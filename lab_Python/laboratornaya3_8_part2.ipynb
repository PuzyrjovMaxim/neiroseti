{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Многослойная-сеть-на-PyTorch\" data-toc-modified-id=\"Многослойная-сеть-на-PyTorch-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span><b>Многослойная сеть на PyTorch</b></a></span><ul class=\"toc-item\"><li><span><a href=\"#Компоненты-нейросети\" data-toc-modified-id=\"Компоненты-нейросети-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span><b>Компоненты нейросети</b></a></span></li><li><span><a href=\"#Многослойная-нейронная-сеть\" data-toc-modified-id=\"Многослойная-нейронная-сеть-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span><b>Многослойная нейронная сеть</b></a></span><ul class=\"toc-item\"><li><span><a href=\"#Forward-pass-в-MLP\" data-toc-modified-id=\"Forward-pass-в-MLP-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Forward pass в MLP</a></span></li></ul></li><li><span><a href=\"#Многослойная-нейросеть-на-PyTorch\" data-toc-modified-id=\"Многослойная-нейросеть-на-PyTorch-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span><b>Многослойная нейросеть на PyTorch</b></a></span></li><li><span><a href=\"#Полезные-ссылки\" data-toc-modified-id=\"Полезные-ссылки-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span><b>Полезные ссылки</b></a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s4wplUzDYJcx"
   },
   "source": [
    "<h2 style=\"text-align: center;\"><b>Многослойная сеть на PyTorch</b></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J2msuyHTYJcx"
   },
   "source": [
    "В этом ноутбке мы научимся писать свои нейросети на фреймворке PyTorch, конкретно - рассмотрим, как написать многослойную полносвязную сеть (Fully-Connected, FC)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9xJnMEZrYJcz"
   },
   "source": [
    "<h3 style=\"text-align: center;\"><b>Компоненты нейросети</b></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "InwacmvIYJc0"
   },
   "source": [
    "Здесь самое время напомнить о том, какие вещи играют принципиальную роль в построении любой ***нейронной сети*** (все их мы задаём *руками*, самостоятельно):  \n",
    "\n",
    "- непосредственно, сама **архитектура** нейросети (сюда входят типы функций активации у каждого нейрона);\n",
    "- начальная **инициализация** весов каждого слоя;\n",
    "- метод **оптимизации** нейросети (сюда ещё входит метод изменения `learning_rate`);\n",
    "- размер **батчей** (`batch_size`);\n",
    "- количество итераций обучения (`num_epochs`);\n",
    "- **функция потерь** (`loss`);  \n",
    "- тип **регуляризации** нейросети (для каждого слоя можно свой);  \n",
    "\n",
    "То, что связано с ***данными и задачей***:  \n",
    "- само **качество** выборки (непротиворечивость, чистота, корректность постановки задачи);  \n",
    "- **размер** выборки;  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tXujEOB0YJc1"
   },
   "source": [
    "<h3 style=\"text-align: center;\"><b>Многослойная нейронная сеть</b></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mnxH-DajYJc3"
   },
   "source": [
    "Как можно понять из названия, многослойная нейросеть состоит из нескольких **слоёв**. Каждый слой состоит из **нейронов**. Ранее мы уже писали свой нейрон на NumPy, вот из таких нейронов и состоит ***MLP (Multi-Layer Perceptron)***. Ещё такую многослойную нейросеть, у которой каждый нейрон на предыдущем уровне соединён с нейроном на следующем уровне, называют ***Fully-Connected-сетью*** (или ***Dense-сетью***).  \n",
    "\n",
    "Расмотрим их устройство более подробно:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "onjJUneMYJc5"
   },
   "source": [
    "* Вот так выглядит двухслойная нейросеть (первый слой - input layer - не считается, потому что это, по сути, не слой):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "owRRulLzYJc6"
   },
   "source": [
    "<img src=\"http://cs231n.github.io/assets/nn1/neural_net.jpeg\" width=300, height=200>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tFNxGGBEYJc8"
   },
   "source": [
    "* Так выглядит трёхслойная нейросеть:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zRaKX35eYJc9"
   },
   "source": [
    "<img src=\"http://cs231n.github.io/assets/nn1/neural_net2.jpeg\" width=400, height=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6w1FTkO1YJc-"
   },
   "source": [
    ".. и так далее для большего случая слоёв."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8iKV7m5YYJc_"
   },
   "source": [
    "**Обратите внимание:** связи есть у нейронов со слоя $L_{i-1}$  и нейронов $L_{i}$, но между нейронами в одном слое связей **нет**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "URV9qWkfYJdA"
   },
   "source": [
    "**Входной слой** -- это данные (матрица $(n, m)$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zK8tWuHHYJdB"
   },
   "source": [
    "Слои, которые не являются входными или выходными, называются **скрытыми слоями (hidden layers)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fz9clUlCYJdC"
   },
   "source": [
    "При решении ***задачи регрессии*** на **выходном слое** обычно один нейрон, который возвращает предсказанные числа (для каждого объекта по числу).  \n",
    "\n",
    "В случае ***задачи классификации*** на **выходном слое** обычно один нейрон, если задача бинарной классификации, и $K$ нейронов, если задача $K$-класовой классификации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nJblXqY5YJdE"
   },
   "source": [
    "#### Forward pass в MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D87xoAl8YJdF"
   },
   "source": [
    "Каждый слой многослойной нейросети - это матрица весов, столбцы которой -- это нейроны (один столбец - один нейрон). То есть один столбец -- это веса одного нейрона."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "RyXUqCfVYJdG",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "Допустим, мы решаем задачу $K$-классовой классификации (на последнем слое $K$ нейронов). Рассмотрим, как в таком случае выглядит `forward_pass` нейросети:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YO6gHbOjYJdH"
   },
   "source": [
    "* Вход: $$X =\n",
    "\\left(\n",
    "\\begin{matrix} \n",
    "x_{11} & ... & x_{1M} \\\\\n",
    "... & \\ddots  & ...\\\\\n",
    "x_{N1} & ... & x_{NM} \n",
    "\\end{matrix}\n",
    "\\right)\n",
    "$$\n",
    "\n",
    "-- матрица $(N, M)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "XdImZiQkYJdI",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "* Структура сети - много слоёв, в слоях много нейронов. Первый слой (после входного) выглядит так:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U2c2M4MJYJdJ"
   },
   "source": [
    "$$ W^1 =\n",
    "\\left(\n",
    "\\begin{matrix} \n",
    "w_{11} & ... & w_{1L_1} \\\\\n",
    "... & \\ddots  & ...\\\\\n",
    "w_{M1} & ... & w_{ML_1} \n",
    "\\end{matrix}\n",
    "\\right)\n",
    "$$\n",
    "\n",
    "-- матрица $(M, L_1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UUCdeLN0YJdK"
   },
   "source": [
    "То есть это в точности $L_1$ нейронов, каждый имеет свои собственные веса, их $M$ штук."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ixHtlMwKYJdL"
   },
   "source": [
    "Мы помним, что нейрон - это линейное преобразование и потом нелинейная функция активации от этого преобразования. Однако в многослойных нейростеях часто отделяют `Linear` часть и `Activation`, то есть слоем считаем набор весов нейронов, а следующий слой всегда функция активации (у всех нейронов из слоя она одна и та же, обычно фреймворки не позволяют задавать конкретному нейрону в слое отличную от других нейронов в этом слое функцию активации, однако это легко сделать, объявив слой из одного нейрона)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AUt1NgTvYJdN"
   },
   "source": [
    "* Другие слои выглядит точно так же, как первый слой. Например, второй слой будет такой:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IdtSTvTmYJdN"
   },
   "source": [
    "$$ W^2 =\n",
    "\\left(\n",
    "\\begin{matrix} \n",
    "w_{11} & ... & w_{1L_2} \\\\\n",
    "... & \\ddots  & ...\\\\\n",
    "w_{L_11} & ... & w_{L_1L_2} \n",
    "\\end{matrix}\n",
    "\\right)\n",
    "$$\n",
    "\n",
    "-- матрица $(L_1, L_2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R3nGnHoLYJdP"
   },
   "source": [
    "То есть это в точности $L_2$ нейронов, каждый имеет свои собственные веса, их $L_1$ штук."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bQhOAQjSYJdR"
   },
   "source": [
    "* Выходной слой:  \n",
    "\n",
    "Пусть в нейросети до выходного слоя идут $t$ слоёв. Тогда выходной слой имеет форму:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fWvqm-K0YJdT"
   },
   "source": [
    "$$ W^{out} =\n",
    "\\left(\n",
    "\\begin{matrix} \n",
    "w_{11} & ... & w_{1K} \\\\\n",
    "... & \\ddots  & ...\\\\\n",
    "w_{L_t1} & ... & w_{L_tK} \n",
    "\\end{matrix}\n",
    "\\right)\n",
    "$$\n",
    "\n",
    "-- матрица $(L_t, K)$, где $L_t$ - количество нейронов в $t$-ом слое, а $K$ -- количество классов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2z5tO89NYJdU"
   },
   "source": [
    "В итоге *для `forward_pass` нам нужно просто последовтельно перемножить матрицы друг за другом, применяя после каждого умножения соответсвующую функцию активации*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IZT4GgsCYJdV"
   },
   "source": [
    "*Примечание*: можно думать об умножении на очередную матрицу весов как на переход в **новое признаковое пространство**. Действительно, когда подаём матрицу $X$ и умножаем на матрицу первого слоя, мы получаем матрицу размера $(N, L_1)$, то есть как будто $L_1$ \"новых\" признаков (построенных как линейная комбинация старых до применения функции активации, и уже как нелинейная комбинация после активации). Здесь уместно вспомнить, что Deep Learning является пообластью Representation Learning, то есть позволяет выучивает новые представляения данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4RhJ4fsHYJdW"
   },
   "source": [
    "**Backward pass в MLP**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MYN043DbYJdX"
   },
   "source": [
    "Обучается с помощью метода \"Error Backpropagation\" - [\"Обратное распространение ошибки\"](https://ru.wikipedia.org/wiki/%D0%9C%D0%B5%D1%82%D0%BE%D0%B4_%D0%BE%D0%B1%D1%80%D0%B0%D1%82%D0%BD%D0%BE%D0%B3%D0%BE_%D1%80%D0%B0%D1%81%D0%BF%D1%80%D0%BE%D1%81%D1%82%D1%80%D0%B0%D0%BD%D0%B5%D0%BD%D0%B8%D1%8F_%D0%BE%D1%88%D0%B8%D0%B1%D0%BA%D0%B8), принцип распространения очень похож на то, как мы обучали один нейрон - это градиентный спуск, но по \"всей нейросети\" сразу.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "oK7Vi4bxYJdZ",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "Backpropagation работает корректно благодаря ***chain rule*** (=правилу взятия производной сложной функции):  \n",
    "\n",
    "Если $f(x) = f(g(x))$, то:  \n",
    "\n",
    "$$\\frac{\\partial{f}}{\\partial{x}} = \\frac{\\partial{f}}{\\partial{g}} \\frac{\\partial{g}}{\\partial{x}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "WKvMsaEBYJda",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "Более подробно про backpropagation можно прочитать здесь (на английском):  https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z5dyjPVNYJdc"
   },
   "source": [
    "<h3 style=\"text-align: center;\"><b>Многослойная нейросеть на PyTorch</b></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T9ufk3ECYJde"
   },
   "source": [
    "Ешё раз напомним про основные компоненты нейросети:\n",
    "\n",
    "- непосредственно, сама **архитектура** нейросети (сюда входят типы функций активации у каждого нейрона);\n",
    "- начальная **инициализация** весов каждого слоя;\n",
    "- метод **оптимизации** нейросети (сюда ещё входит метод изменения `learning_rate`);\n",
    "- размер **батчей** (`batch_size`);\n",
    "- количетсво **эпох** обучения (`num_epochs`);\n",
    "- **функция потерь** (`loss`);  \n",
    "- тип **регуляризации** нейросети (для каждого слоя можно свой);  \n",
    "\n",
    "То, что связано с ***данными и задачей***:  \n",
    "- само **качество** выборки (непротиворечивость, чистота, корректность постановки задачи);  \n",
    "- **размер** выборки;  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9KrWarqTYJdf"
   },
   "source": [
    "Cоздадим двухслойную нейросеть из 100 нейронов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T16:51:28.808520Z",
     "start_time": "2024-04-25T16:51:28.803161Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "bLjkPg19YJdg"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iCDVRvQJYJdl"
   },
   "source": [
    "Генерация и отрисовка датасета:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T16:51:33.041500Z",
     "start_time": "2024-04-25T16:51:33.032811Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "k0J27RcLYJdm"
   },
   "outputs": [],
   "source": [
    "N = 100\n",
    "D = 2\n",
    "K = 3\n",
    "X = np.zeros((N * K, D))\n",
    "y = np.zeros(N * K, dtype='uint8')\n",
    "\n",
    "for j in range(K):\n",
    "    ix = range(N * j,N * (j + 1))\n",
    "    r = np.linspace(0.0, 1, N)\n",
    "    t = np.linspace(j * 4, (j + 1) * 4,N) + np.random.randn(N) * 0.2 # theta\n",
    "    X[ix] = np.c_[r * np.sin(t), r * np.cos(t)]\n",
    "    y[ix] = j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X9FHhqX_YJdp"
   },
   "source": [
    "Не забываем оборачивать данные (без этого градиенты не посчитать):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T16:51:37.013010Z",
     "start_time": "2024-04-25T16:51:37.007378Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "pQINaQqZYJdq"
   },
   "outputs": [],
   "source": [
    "X = torch.autograd.Variable(torch.FloatTensor(X))\n",
    "y = torch.autograd.Variable(torch.LongTensor(y.astype(np.int64)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T16:51:39.235190Z",
     "start_time": "2024-04-25T16:51:39.229790Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Who9mS8oYJdu",
    "outputId": "1ec6e30a-2cd9-4bd6-d0e0-3b7c936d1b8a"
   },
   "outputs": [],
   "source": [
    "print(X.data.shape, y.data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I-9dFW5CYJd0"
   },
   "source": [
    "Сама ячейка с нейросетью и обучением:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T16:51:44.986666Z",
     "start_time": "2024-04-25T16:51:43.411807Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "kf-YapleYJd1",
    "outputId": "d71315ae-670a-48e3-bcf7-b425ebe198fe"
   },
   "outputs": [],
   "source": [
    "# N - размер батча (batch_size, нужно для метода оптимизации); \n",
    "# D_in - размерность входа (количество признаков у объекта);\n",
    "# H - размерность скрытых слоёв; \n",
    "# D_out - размерность выходного слоя (суть - количество классов)\n",
    "N, D_in, H, D_out = 64, 2, 100, 3\n",
    "\n",
    "# Use the nn package to define our model and loss function.\n",
    "two_layer_net = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in, H),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H, D_out),\n",
    ")\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(size_average=False)\n",
    "\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.SGD(two_layer_net.parameters(), lr=learning_rate)\n",
    "for t in range(500):\n",
    "    # forward\n",
    "    y_pred = two_layer_net(X)\n",
    "\n",
    "    # loss\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    print('{} {}'.format(t, loss.data))\n",
    "\n",
    "    # зануляем градиенты (чтобы не было остатка с редыдущего шага)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # backward\n",
    "    loss.backward()\n",
    "\n",
    "    # обновляем\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zTQiN0bcYJd6"
   },
   "source": [
    "**Обратите внимание:** несмотря на то, что это задача 3-х классовой классификации и столбец $y$ нужно по-хорошему кодировать OneHotEncoding'ом, мы подали просто столбец из 0, 1 и 2 и всё отработало. Дело в том, что PyTorch сам делает OneHot в таком случае."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "apsWWq17YJd8"
   },
   "source": [
    "Проверим, насколько хороша наша сеть из 100 нейронов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T16:51:49.653751Z",
     "start_time": "2024-04-25T16:51:49.648544Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "X0ICB6Z-YJd-"
   },
   "outputs": [],
   "source": [
    "# Обратно в Numpy для отрисовки\n",
    "X = X.data.numpy()\n",
    "y = y.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T16:51:53.721565Z",
     "start_time": "2024-04-25T16:51:52.383326Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "JvjfvgbPYJeB",
    "outputId": "cf5545ff-3315-45c9-c674-af44f63a346b"
   },
   "outputs": [],
   "source": [
    "h = 0.02\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "grid_tensor = torch.FloatTensor(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "Z = two_layer_net(torch.autograd.Variable(grid_tensor))\n",
    "Z = Z.data.numpy()\n",
    "Z = np.argmax(Z, axis=1)\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "plt.contourf(xx, yy, Z, cmap=plt.cm.rainbow, alpha=0.3)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap=plt.cm.rainbow)\n",
    "\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "\n",
    "plt.title('Спираль', fontsize=15)\n",
    "plt.xlabel('$x$', fontsize=14)\n",
    "plt.ylabel('$y$', fontsize=14)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G2wNgoh5YJeG"
   },
   "source": [
    "Подберём гиперпараметры получше:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не забываем оборачивать данные (без этого градиенты не посчитать):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T17:05:25.503949Z",
     "start_time": "2024-04-25T17:05:25.495186Z"
    }
   },
   "outputs": [],
   "source": [
    "N = 100\n",
    "D = 2\n",
    "K = 3\n",
    "X = np.zeros((N * K, D))\n",
    "y = np.zeros(N * K, dtype='uint8')\n",
    "\n",
    "for j in range(K):\n",
    "    ix = range(N * j,N * (j + 1))\n",
    "    r = np.linspace(0.0, 1, N)\n",
    "    t = np.linspace(j * 4, (j + 1) * 4,N) + np.random.randn(N) * 0.2 # theta\n",
    "    X[ix] = np.c_[r * np.sin(t), r * np.cos(t)]\n",
    "    y[ix] = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T17:05:27.466336Z",
     "start_time": "2024-04-25T17:05:27.460049Z"
    }
   },
   "outputs": [],
   "source": [
    "# оборачиваем данные\n",
    "X = torch.autograd.Variable(torch.FloatTensor(X))\n",
    "y = torch.autograd.Variable(torch.LongTensor(y.astype(np.int64)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T17:05:29.317656Z",
     "start_time": "2024-04-25T17:05:29.312175Z"
    }
   },
   "outputs": [],
   "source": [
    "N, D_in, H, D_out = 64, 2, 100, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T17:05:31.055411Z",
     "start_time": "2024-04-25T17:05:31.048571Z"
    }
   },
   "outputs": [],
   "source": [
    "#создаем сеть better_net с 4-мя слоями\n",
    "better_net = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in, H),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H, H),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H, H),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H, D_out),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T17:05:33.097103Z",
     "start_time": "2024-04-25T17:05:33.092951Z"
    }
   },
   "outputs": [],
   "source": [
    "# функция потерь как и раньше Кроссэнтропия\n",
    "loss_fn = torch.nn.CrossEntropyLoss(size_average=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T17:05:35.275989Z",
     "start_time": "2024-04-25T17:05:35.270241Z"
    }
   },
   "outputs": [],
   "source": [
    "# learning rate задаём 1e-3\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T17:05:37.064559Z",
     "start_time": "2024-04-25T17:05:37.059619Z"
    }
   },
   "outputs": [],
   "source": [
    "#оптимизатор не меняем\n",
    "optimizer = torch.optim.SGD(better_net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T17:05:43.243145Z",
     "start_time": "2024-04-25T17:05:40.479102Z"
    }
   },
   "outputs": [],
   "source": [
    "# обучаем на 1000 эпохах\n",
    "for t in range(1000):\n",
    "    # forward\n",
    "    y_pred = better_net(X)\n",
    "\n",
    "    # loss\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    print('{} {}'.format(t, loss.data))\n",
    "\n",
    "    # зануляем градиенты (чтобы не было остатка с редыдущего шага)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # backward\n",
    "    loss.backward()\n",
    "\n",
    "    # обновляем\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T17:03:58.674433Z",
     "start_time": "2024-04-25T17:03:58.328511Z"
    }
   },
   "outputs": [],
   "source": [
    "h = 0.02\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "grid_tensor = torch.FloatTensor(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "Z = better_net(torch.autograd.Variable(grid_tensor))\n",
    "Z = Z.data.numpy()\n",
    "Z = np.argmax(Z, axis=1)\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "plt.contourf(xx, yy, Z, cmap=plt.cm.rainbow, alpha=0.3)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap=plt.cm.rainbow)\n",
    "\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "\n",
    "plt.title('Спираль', fontsize=15)\n",
    "plt.xlabel('$x$', fontsize=14)\n",
    "plt.ylabel('$y$', fontsize=14)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предлагается самостоятельно проанализировать то, что было изменено, чтобы улучшить качество модели (и *обратить на это внимание*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6N_9wfvPYJeK"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H_thmQJOYJeK"
   },
   "source": [
    "<h3 style=\"text-align: center;\"><b>Полезные ссылки</b></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RpSrLf9FYJeL"
   },
   "source": [
    "1). *Примеры написания нейросетей на PyTorch (офийиальные туториалы) (на английском): https://pytorch.org/tutorials/beginner/pytorch_with_examples.html#examples  \n",
    "https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html*\n",
    "\n",
    "2). Курс Стэнфордского Университета:  http://cs231n.github.io/\n",
    "\n",
    "3). Практически исчерпывающая информация по основам нейросетей (из cs231n) (на английском):  \n",
    "\n",
    "http://cs231n.github.io/neural-networks-1/,  \n",
    "http://cs231n.github.io/neural-networks-2/,  \n",
    "http://cs231n.github.io/neural-networks-3/,  \n",
    "http://cs231n.github.io/neural-networks-case-study/#linear\n",
    "\n",
    "4). *Хорошие статьи по основам нейросетей (на английском):  http://neuralnetworksanddeeplearning.com/chap1.html*\n",
    "\n",
    "5). *Наглядная демонстрация того, как обучаются нейросети:  https://cs.stanford.edu/people/karpathy/convnetjs/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1Qldb1U5YJeM"
   },
   "source": [
    "6). *Подробнее про backpropagation -- статья на Medium: https://medium.com/autonomous-agents/backpropagation-how-neural-networks-learn-complex-behaviors-9572ac161670*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g1HSslRhYJeN"
   },
   "source": [
    "7). *Статья из интернета по Backprop: http://page.mi.fu-berlin.de/rojas/neural/chapter/K7.pdf*"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "[seminar]mlp_pytorch.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
